---

layout: post
title: Data Catalog 만들기 - Backend 주요 기능
date: 2024-04-20 18:05:23 +0900
category: DE
use_math: true
tags:
- 데이터 민주화
- 데이터 거버넌스
- 데이터 엔지니어
- 데이터 신뢰성
- 데이터 카탈로그
- Data Catalog
- Metadata
- 메타데이터


---

# Data Catalog 만들기 - Backend 주요 기능

이 내용은 [Data Catalog 만들기 책](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=272623760&start=slayer)을 읽고 3장(Data Catalog 주요 기능 만들기)의 일부를 읽고 리뷰하는 글 입니다.

## Data Catalog란 무엇인가?

이 책의 저자는 Data Catalog라는 용어에 대해서 다음과 같은 문장으료 표현합니다.

- 사용자의 데이터 전달 플랫폼
- 데이터 자산화 도구
- 다양한 데이터 서비스 간의 연계자

Data Catalog는 **데이터 사용자들이 필요로 하는 데이터에 대한 접근을 쉽게 도와주고**, 단순히 **파일 혹은 스키마와 같이 범용적인 형태로 저장되어 있는 데이터를 통합적으로 관리 할 수 있는 자산으로서 변환해주고**, **다양한 데이터 서비스에서의 접근을 용이하게 하고 그 결과를 다시 Catalog화 하여 연계하는 역할**을 합니다.

## Data Catalog 주요 기능 중 Backend단에서 구축되어야 하는 기능

Data Catalog를 구축하는 과정에서 Backend 단에서 구축되어 자동화되어야 하는 기능들이 있습니다. 이번 장에서는 이 기능들에 대해 알아보겠습니다.

### 메타데이터 수집

가장 기본이 되는 메타데이터 수집입니다. 이 목차는 메타데이터를 수집하는 과정에서 어떤 부분을 고려해야하는지 혹은 그 범위에 대해 말하고 있습니다.

읽으면서 확실히 이번 데이터 카탈로그 구축에서 고려 할 부분이 보여서 개인적으로 마음에 드는 내용이였습니다.

#### 사내 데이터 아키텍처(DA)의 관리 대상 확인

RDB 뿐만 아닌 데이터 파이프라인에 활용되는 플랫폼과 문서형, 혹은 분석에 사용되는 데이터 플랫폼에 대해서도 모두 메타데이터를 수집해야 한다고 합니다.

#### 전사 데이터 아키텍처(DA) 시스템에 대한 현행화

데이터 아키텍처의 현행화라는 건 결국 **데이터 카탈로그**를 지속적으로 최신화 하는 것입니다. 쿼리와 대시보드 및 보고서, 데이터 활용에 이해를 돕는 지식등을 현행화하고 지속적으로 수집 및 관리하는 것을 자동화해야합니다.

현재 활용중인 Datahub에서 배치 및 Push 방식으로 동작하는 최신화와 유사하다고 생각합니다.

Datahub에서는 총 3가지의 메타데이터를 담는 데이터베이스를 지원하고, 활용하지만 만약 별도의 툴을 사용하지 않는다면 다음과 같은 부분을 참고하여 메타데이터 데이터베이스를 구축해야 한다고 합니다.

- 다양한 데이터 객체를 포함
	- 정형화되어있지 않은 형식(JSON, 정형 데이터, 이미지 등)을 담을 수 있어야 합니다.
- 다양한 유형의 데이터를 담을 수 있어야 합니다.
	- 데이터 명, 오너십, 태그, 설명 등
- 상당히 큰 저장공간이 필요합니다.
	- 메타데이터는 단순히 스키마의 정보정도만 담고있지 않습니다. 설명, 태그, 오너십을 포함하여 검색에 활용 될 수 있는 다양한 정보들과 그 관계성을 지키기 위한 속성 등 다양한 정보가 포함되어 생각보다 많은 용량을 사용합니다.
- 각 빅데이터 플랫폼과의 호환성
	- 빅데이터 플랫폼에서 해당 정보를 활용 할 수 있어야 합니다.

### 메타데이터 추천

제가 가장 의문을 품고있는 부분이면서 가장 필요한 부분이라고 생각되어지는 내용입니다.

현재 Datahub을 구축하면서 가장 어려운 부분은 **"어떻게 이 많은 데이터를 다 입력하는가"**에 대한 내용입니다. 지금까지 쌓아온 수많은 데이터셋이 있고, 이 데이터셋에 대해서 지금까지 제대로 된 메타데이터를 입력하지 않은 상황이였다면, 처음 카탈로그를 구축하면서 이 내용은 너무나도 큰 작업 비용이 소모됩니다.

이 부분에 대해서는 Agent라는 ML 모델을 만든 뒤 메타데이터를 생성하는 방식으로 해당 페이지를 추천합니다. 이 작업이 어떻게 진행되는지 의문은 있지만, 어느정도 고려 할 필요가 있다고 생각합니다.

Agent는 해당 객체에 대해서 대략적인 키워드를 메타데이터에 포함하여 추후 검색등에 잘 활용 할 수 있도록 만드는 ML 모델입니다.

### 검색엔진 색인

### 쿼리 로그 수집/파싱

최근 쿼리 로그를 수집하여 파싱 및 분석하는 방향에 대해서 매우 큰 관심을 가지고 있습니다. 마침 이 내용에서도 이런 부분에 대해서 이야기하고 있습니다.

쿼리 로그를 수집하여 활용하면 다음과 같은 내용을 알 수 있습니다.

- 테이블의 사용 현황에 대해 알 수 있습니다.
- 슬로우 쿼리 및 불필요한 쿼리를 추적 할 수 있습니다.
- 프롬프트 방식으로 쿼리를 추천하거나 작성 할 수 있게 됩니다.
- Datahub에서 제공하지만, Lineage를 확인 할 수 있습니다.

AD-HOC 작업을 지속적으로 하다보면 테이블이 계속 쌓이는 상황에 마주하게 됩니다. 이 경우 어떤 데이터가 활용되는 지 알 수 없으면 삭제 및 변형했을 때 어떤 문제가 발생하는지 알기 어려 울 수 있습니다.

### 데이터 프로파일링

데이터 프로파일링도 매우 중요한 요소입니다. 수집 및 종합 된 데이터의 형식이나 값을 미리 프로파일링하여 제대로 적재 되었는지에 대해서 미리 확인 할 수 있습니다.

책에서는 프로파일링에 대해서 다음의 분류로 나누었습니다.

#### 데이터 유형

문자열, 정수형, NULL 등의 데이터 유형에 대해서 파악하는 프로파일링입니다.

특정 데이터베이스나 저장소에서 해당 데이터의 컬럼이 어떤 유형인지를 확인하는 프로파일링입니다.

#### 데이터 값

데이터 값의 프로파일링은 단순히 스키마 내 컬럼 정보를 얻는 데이터 유형 프로파일링과는 다르게 실제 값을 스캔하여 값에 대한 통계치 등을 프로파일링하는 것 입니다.

주로 다음과 같은 프로파일링이 있습니다.

- 전체 데이터의 건수를 파악하기 위한 '총 데이터 건수'
- 유일 한 값의 건수를 파악하기 위한 '유일 데이터 건수'
- 값이 비어있는 'NULL 데이터 건수'
- 카테고리 유형 데이터에 분포
- 데이터 구간 별 비중
- 데이터 범위의 Min/Max

#### 데이터 포맷

데이터 포맷은 특정 데이터가 가져야 하는 유형의 포맷에 대해서 프로파일링하는 방식입니다.

다음과 같은 프로파일링이 있습니다.

- 날짜 형식에 대한 포맷
- 데이터 길이


### 데이터 활용 집계

Data Catalog의 세부 기능 별 활용 현황을 집계해야한다고 합니다. 이를 위해서는 무조건 **사용자별 Data Catalog 활용 로그**를 모두 남겨야 하며 각 세부 기능별로 집계를 진행해야 합니다.

여기서 Data Catalog 활용은 Data Catalog에서의 검색, 수집 요청, 조회, 큐레이션, 생성, 카탈로그 등록 등의 모든 기록을 말합니다. 

그리고 그 로그를 활용하여 다음의 용도로 사용 할 수 있습니다.

- 검색 로그를 활용하여 자동완성 기능과 우선순위 설정으로 활용 할 수 있습니다.
- 조회 로그는 추천과 유저 클러스터링, 개인화 카탈로그 추천 등으로 이어질 수 있습니다.
- 수집 요청 로그는 개인화 추천에 활용 할 수 있습니다.
- 다양한 로그를 통해 사용자 및 관계자를 파악하여 오너십을 설정하는 과정도 단순화 할 수 있습니다.

### 


