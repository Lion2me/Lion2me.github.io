---

layout: post
title: 데이터 민주화와 셀프서비스 데이터 - 피처 저장소 서비스
date: 2023-10-15 18:05:23 +0900
category: DE
use_math: true

---

# 데이터 이동 서비스 및 클릭스트림 추적 서비스

이 글은 데이터 민주화와 셀프서비스 데이터를 읽고 쓰는 포스트입니다. 이 장에서는 주요하게 다루는 내용이 **"데이터 이동 서비스와 클릭스트림 추적 서비스"**에 대한 내용입니다.

## 데이터 이동 서비스

데이터 이동 서비스라는 말은 상당히 많은 부분을 포함한 개념이라고 생각합니다. 이 책에서는 데이터가 이동하는 전체 프로세스에 대해서 이야기하고 있습니다.

가장 대표적인 예를 들면 다음과 같은 예시가 있습니다.

1. 데이터 레이크에 적재 된 데이터를 ETL을 통해 집계 결과 수집을 자동화 하는 것
2. 원시 데이터를 쿼리 엔진에 옮기는 것
3. 데이터베이스의 변동 사항을 메시지 브로커에 전달하는 것

이 외에도 데이터가 이동하는 모든 방향성에 대해서 책은 이야기하고 있습니다. 이 점에 주의해서 주요한 내용이라고 생각되는 부분만 되새기기 위해 적어보겠습니다.

### 고려해야 하는 부분

이 부분에서 주요하게 이야기되는 지점 중 하나는 **스키마의 변경으로 인해 쿼리 결과 변형**이 있었습니다. 이 부분은 실제로 최근 전달받은 업무에서도 이러한 문제로 인해 장애가 있었기 때문에, 한번 더 짚으면 좋을 것 같았습니다.

위 내용을 조금 더 깊에 들어가면 **의존성**에 관련한 내용으로 키울 수 있을 것 같습니다. 스키마가 변경되었을 때, 컬럼의 순서가 바뀌었을 때와 같이 버전이 업데이트 되었을 때 읽기 스키마를 기반으로 이전 버전의 스키마를 그대로 읽을 수 있는지가 중요하게 생각되어지는 것 같습니다.

Parquet나 Avro와 같은 스키마에 대한 정보를 어느정도 가지고 있는 파일의 경우 이런 문제를 대체로 해결이 가능합니다. 그래서 **어떤 형식으로 데이터를 저장 할 것**인지가 상당히 중요한 부분입니다.

두 번째로는 **규모가 어떻게 변경 될 수 있는가?**에 대한 내용이 있습니다. 시간이 지날수록 데이터가 쌓이는데 **행의 갯수, 용량, 지속적으로 복사해야하는 테이블 수**는 항상 고려해야 합니다.

세 번째로는 **수집 패턴**입니다.

수집 패턴으로는 일괄 수집, 변경 데이터(CDC) 수집, 이벤트 집계 패턴등이 있습니다.

일괄 수집 패턴은 대체로 장애 복구에 용이하고, 유효성 검사도 간편합니다. 하지만 증분 테이블에 대한 새로고침 지원이나 변환 기능에 제한이 있으며, 성능에 잠재적으로 영향을 미칠 수 있습니다. 이러한 성능 문제는 보통 스냅샷만 가져와서 다른 플랫폼으로 옮긴 후 별도로 OLAP 용으로 사용하기도 합니다.

변경 데이터 수집 패턴은 debezium과 같은 CDC 어댑터가 있습니다. 대체로 스키마의 변경이나 데이터의 업데이트 내용 등, 변경 로그(binlog와 같은)를 사용하여 원하는 정보를 얻을 수 있도록 되어 있습니다. 이러한 시스템을 이용해서 다른 데이터  플랫폼이 서비스 데이터베이스와 실시간으로 동일한 정보를 가지고 있을 수 있도록 할 수 있습니다.

이벤트 집계 패턴은 순수 유저의 로그 정보를 집계하여 활용하는 패턴입니다. 예를들면 유저의 nginx로 구축 된 웹 서버에 접속하면 찍히는 기본적인 log를 fluentd를 통해 실시간으로 수집하고 형식에 맞게 변형하여 적재한다면, 이러한 이벤트 집계 패턴에 해당합니다.

이벤트 집계 패턴의 강점은 다음과 같습니다.

1. 로그와 이벤트에 최적화된 실시간 솔루션입니다. 신뢰성, 가용성이 높고 확장성이 뛰어납니다.
2. 소스 성능에 미치는 영향을 최소화 합니다.
3. 확장성과 커스터마이징이 용이하고, 운영 오버헤드를 최소화합니다.
4. 데이터 이동 프로세스 중 필터링과 데이터 변환을 지원합니다.
5. 대량의 로그 및 이벤트 데이터를 처리하도록 확장됩니다.

이벤트 집계 패턴의 약점은 다음과 같습니다.

1. 소스 이벤트에 대한 정렬을 보장하지 않습니다.
2. 메시지를 정확히 한 번(exactly once)가 아닌 최소 한 번(least once) 전달하기 때문에 대상에서 중복 이벤트를 처리해야 합니다.

---

## 클릭스트림 추적 서비스

기존의 클릭스트림 데이터의 활용이 증가하면서 클릭스트림 데이터의 수집, 보강, 소비와 관련해서 생겨난 3가지 문제점에 대해서 이야기해줍니다.

1. 데이터 사용자는 분석 요구 사항에 따라 제품 및 웹 페이지에 새로운 추적 비콘을 지속적으로 추가합니다.
	- 이 때마다 위치 선정, 라이브러리, 분류를 위한 전문지식이 필요합니다.
2. 클릭스트림 데이터는 인사이트 생성에 사용되기 전에 집계, 필터링, 보강되어야 합니다.
	- 봇 생성 트래픽을 필터링해야 부하를 최소화 할 수 있습니다.
3. 클릭스트림 분석은 트랜잭션 기록과 실시간 클릭스트림 데이터에 대한 액세스를 필요로 합니다.
	- 개인화 서비스에서 클릭스트림은 준실시간으로 이루어 질 수 있는데, 이 경우 클릭 시간 지표에 영향을 미칩니다.

이상적인 셀프서비스 클릭스트림 서비스는 **SaaS 애플리케이션 및 마케팅 웹 페이지 내에서 계측 비콘의 작성을 단순화**하는 것이라고 합니다.

### 고려해야 하는 부분

첫 번째로 **각 클릭스트림 데이터를 도메인마다 개별적으로 전송하되 추적 스키마의 속성 값을 일관되게 설정**하는게 좋습니다. 이렇게 속성을 정하는 과정에서 다음과 같은 체크리스트를 읽어보면 좋을 것 같습니다.

1. 이벤트에서 캡처된 속성
	- 누가, 무엇을, 어디서, 도메인의 속성, 이벤트의 유형
2. 클라이언트 측 이벤트 수집
	- 모바일 클라이언트, 데스크톱 응용프로그램, 웹 응용프로그램의 인벤토리
3. 타사 소스 수집
	- 구글, 페이스북, 광고 대행사 등 타사 소스의 로그 데이터와 통계를 집계
4. 서버 측 이벤트 수집
	- 백엔드 애플리케이션 서버에서 이벤트 캡처 여부 결정
5. 속도와 피드
	- 비콘 수, 이벤트 생성 비율, 이벤트 보존 기간에 대한 대략적인 추정치

두 번째로는 **고객 행동을 더 잘 이해 할 수 있도록 세션으로 나누어야** 합니다. 전환율이 가장 높은 페이지를 추적하거나 사용자의 행동을 통한 마케팅 전략을 세우는 과정에서 특정 유저의 이벤트를 연이어 추적하는것이 효과적입니다.

클릭스트림 추적 데이터에서 수집 할 수 있는 데이터 외에도 다양한 컨텍스트를 추가하여 유의미한 데이터를 만들어 수집하거나 봇 필터링등을 통해 효과적인 수집을 만들어야 합니다.

클릭스트림 데이터를 보강하는 과정에서 읽어보면 좋은 체크리스트는 다음과 같습니다.

1. 봇 필터링
	- 실제 사용자 활동 중에서 봇 트래픽을 필터링합니다.
	- 페이지 히트, 쿠키 허용, 깊이(폭)우선 사이트 검색, 특정 운영체제의 접근 패턴
2. 사용자 에이전트 구문 분석
	- 브라우저 유형과 모바일인지 데스크톱인지 등 추가 세부사항을 연결합니다.
	- 유저의 활동 차이를 분석 할 수 있습니다.
3. IP2Geo
	- IP를 통해 위치 추적
4. 세션화
	- 특정 세션 및 세션 전체에서 사용자의 활동을 분석
5. 다양한 시간대에 걸친
	- 개별 이벤트의 세부 정보와 장기간의 사용자 추세를 확인하는 등의 요구사항에서 활용됩니다.
6. 개인정보 필터링
	- IP, 계정 등 민감정보를 필터링 할 수 있습니다.





