---

layout: post
title: 데이터의 사용성과 정확성 관점에서 데이터 거버넌스의 필요성과 데이터 카탈로그 구축이 선행되어야 하는 이유
date: 2024-05-11 18:05:23 +0900
category: DE
use_math: true
tags:
- 데이터 민주화
- 데이터 거버넌스
- 데이터 엔지니어
- 데이터 신뢰성
- 데이터 카탈로그
- Data Catalog
- Data Governance
- Metadata
- 메타데이터


---

# 서론

이 포스트에서는 현재까지 얻은 데이터 거버넌스에 대한 이해를 기반으로 **데이터 거버넌스가 무엇인지 정리**하고 **데이터 카탈로그에 대해 정리** 한 뒤 **왜 데이터 카탈로그를 선행해야 하는지** 알아봅니다.

처음으로 데이터 거버넌스에 대해 연구하고, 현재 재직중인 회사에서 이러한 이론을 적용하고자 하는 상황에서 많은 어려움 겪고 기존 레거시 환경에 대해 우선순위를 혼동하며 조금씩이나마 개념을 확립해나가며 적는 글로써 부족한 글 일지라도 많은 엔지니어분들께 도움이 되고자 합니다.

# 데이터 거버넌스란

데이터 거버넌스를 정의하는 글은 많습니다. 하지만 공통적으로 포함 된 키워드는 바로 **"데이터 보안, 개인정보 보호, 사용성, 가용성, 정확성"** 입니다. 데이터 거버넌스란 이러한 키워드를 보장하기 위해 수행하는 모든 작업을 일컫습니다.

문제점은 이러한 영역이 너무나 광범위하다는 점입니다. 설명으로 알 수 있지만, 데이터 거버넌스는 단순히 어떠한 데이터를 어떻게 생성하고 어떻게 제공 할 것인지를 넘어서 해당 데이터가 얼마나 사용되는지, 얼마나 정확한지, 포함되지 않아야 하는 데이터가 포함되어 있는지, 얼마나 오랫동안 저장 될 것인지를 모두 포함합니다.

마치 초콜릿을 판매하기 위해 카카오 농장의 부지 매입부터 소매상의 가판대에 오르기까지의 모든 과정에 대한 규격이라고 말 할 수 있을 것 같습니다. 앞으로 이어지는 글에서는 일부 정보를 사용자에게 제공되는 데이터를 초콜릿으로 비유하여 적어보겠습니다.

# 데이터 거버넌스의 필요성

개인적인 의견으로는 데이터 거버넌스를 확립해야하는 이유는 **"데이터 팀에게 데이터는 곧 상품이기 때문"** 이라고 생각합니다. 흔히 대한민국의 많은 데이터 팀은 데이터를 마치 수작업(Hand-made)으로 만든 상품으로 생각합니다. 수작업 상품의 이미지는 대체로 고급스럽고 비싸며, 맞춤형이고, 희소한 이미지입니다. 하지만 대부분의 데이터는 그렇게 소비되지 않고, 데이터 팀은 수작업 데이터 작업을 최소화 해야 합니다.

대부분의 소비자는 정확히 원하는 수준의 당도를 가진 초콜릿을 꼼꼼하게 따져가며 요청하지 않습니다. 마트에서 적당히 자신이 원하는 당도에 맞거나, 양이 맞거나, 조건이 맞는 초콜릿을 구매해서 편하게 소비합니다. 소비자 본인은 까다로운 소비자라고 생각할지라도 소비하는 패턴은 대체로 기성품에 가까우며 우리가 기성품을 소비하는 이유가 바로 그런 니즈를 적당히 충족시켜 줄 기성품이 있기 때문입니다. 즉, **목적에 맞는 기성품(범용적인 것)이 있다면 수작업으로 만들 상품은 많지 않다**는 의미 입니다.

수작업 데이터는 다양한 별개의 사항을 가지고 있습니다. 극히 제한적인 사용 부서, 개인정보 보호 및 보안의 개별적인 레벨, 원천에 가까운 데이터의 의존관계, 제한적인 목적을 위해 만들어졌기에 파생 데이터 작성의 어려움, 작은 비즈니스 변화로 인한 세부 쿼리의 잦은 변화 및 사이드 이펙트 취약 등이 있을 수 있습니다.

보통 AD-HOC 성 업무로 얻는 일시적인 대시보드를 위해 만들어진 작은 규모의 데이터가 이러한 수작업 데이터의 대표적인 예시 입니다. 물론 이러한 업무는 중요한 업무 일 수 있고 이로인해 많은 비즈니스적인 인사이트를 얻을 수 있음은 사실입니다.

하지만 저의 생각에 다음의 상황이 발생하면 데이터 거버넌스가 필요한 상황이 아닐지 고려해봐야 할 것 같습니다.

- AD-HOC 업무가 너무 많이 발생한다.
- 하나의 AD-HOC 업무가 너무 오래 걸린다.
- 이전에 비슷한 AD-HOC 업무를 처리 한 경험이 있다.
- AD-HOC 업무로 얻은 지표에 대해 신뢰성이 의심된다. 혹은 검증까지 너무 오랜 시간이 걸린다.
- 이 외에도 다양한 상황

이러한 모든 상황은 결국 데이터의 **사용성, 정확성이 떨어지기 떄문**이라고 의심 할 수 있습니다. AD-HOC 업무로 만들어지는 최종 결과물은 하나의 테이블 또는 대시보드로 이것을 우리는 완성된 초콜릿이라고 생각하고 위 문제에 대해 간략히 이야기해보겠습니다.

## AD-HOC 업무가 너무 많이 발생하는건 어째서인가

이 경우 소비가 많아지기에 완성된 초콜릿이 많아지는건 좋은 상황 일 수 있습니다. 하지만 확실 한 상황은 "소비자가 초콜릿을 만들지 못하는 상황"임은 확실해보입니다.

간단한 초콜릿은 소비자도 만들 수 있습니다. 우리는 발렌타인데이에 초콜릿을 만들 수 있는 중간 재료인 카카오 매스 혹은 조금 더 가공 된 커버춰 초콜릿 등이 실제 마트에서 파는 초콜릿의 판매 비중을 어느정도 줄인다는 것을 알고 있습니다. 그러면 우리가 데이터를 만들기 위한 중간 데이터를 잘 갖추어놓으면 이러한 문제를 해결 할 수 있습니다.

갖추어진 중간 데이터로 사용자가 직접 만든 데이터가 바로 수작업 데이터입니다. 데이터 팀에서는 이러한 수작업 데이터를 직접 만들 필요가 없이 그들이 직접 만들 수 있는 환경을 구축해주면 됩니다. 이러한 환경이 데이터 민주화입니다.

## 하나의 AD-HOC 업무가 너무 오래 걸린다.

이러한 문제도 많은 AD-HOC 업무 발생과 비슷하게 "사용성" 문제 일 가능성이 높습니다. "우리는 카카오를 곧바로 하나의 초콜릿을 만들고 있는 것이 아닐까?" 하는 의심이 필요합니다. 사실은 이미 만들어진 카카오 매스와 커버춰 초콜릿을 녹여서 만들면 해결 될 수 있을지 모릅니다.

카카오(원천 데이터)에서 하나의 초콜릿(대시보드에 가까운 데이터)을 곧바로 만드는 것이 옳은 행동이 아니라는 것은 알고 있을 것이라 생각합니다.

## 이전에 비슷한 AD-HOC 업무를 처리 한 경험이 있다.

마트에서 초콜릿을 보면 카카오의 함량은 체계화 되어 있습니다. 예를 들면 카카오 56%가 포함 된 초콜릿 옆에 카카오 함량이 57%인 초콜릿이 놓여있지 않습니다. 그리고 56% 함량의 초콜릿이 조금 달다고해서 57% 함량의 초콜릿을 만들지 않습니다.

현재 많은 비즈니스 관계자는 기존에 거의 동일한 지표가 있음에도 1% 추가 함량을 위해 새로운 지표를 만들기를 바라는 경우가 있습니다. 그 이유는 대체로 팀의 성과를 최대화 할 수 있는 방향으로 대시보드를 보고 싶기에 요청 한 것일 가능성이 있습니다.

우리는 초기에 56% 함량의 초콜릿을 만들기 시작했을 때 즉, 결과 데이터를 만들 때 확실하게 짚고 넘어 갈 점이 있습니다. 바로 "이 함량이 가장 대중적으로 잘 팔릴 수 있는 비율" 이라는 의사결정입니다. 그러기 위해서 데이터에 대한 메타데이터를 잘 적재 할 필요가 있습니다.

## AD-HOC 업무의 검증과 신뢰성

초콜릿 공장에서 만들어진 초콜릿이 정확히 원하는 카카오가 사용되었는지, 함량이 정확한지, 무게가 적절한지, 맛이 동일한지에 대해서 검증하기 위해서는 초콜릿이 만들어지는 각 공정에 대한 신뢰성이 필요합니다.

카카오로 카카오 매스를 만드는 과정에서 발생하는 발효, 블랜딩, 기타 공정에서 발생하는 장애를 명확하게 확인 할 수 있어야 합니다. 또한 카카오 매스를 가공해서 시판 초콜릿을 만드는 공정에서 발생하는 장애도 명확하게 확인 할 수 있어야 합니다. 이렇듯 각 공정에서 장애가 발생 했을 때 즉시 이 사실을 알 수 있는 환경을 구축해야합니다.

만약 이 사실을 알 수 있는 환경을 구축하는 것이 어렵다면 "현재 하나의 공정에서 너무 많은 작업을 하는게 아닌가?" 라는 의심을 할 필요가 있습니다. 카카오를 초콜릿으로 만드는 공정을 하나로 만들어버린다면, 우리는 각 공정에서 나온 결과물에 대한 검증을 할 수 있는 시간과 공간이 없습니다. 데이터를 다루는 사람들이 흔히 듣는 말로 "한 번의 변환이 크면 클수록 데이터의 신뢰성은 떨어진다." 를 염두하여 한 번의 변환에 대한 규모를 쪼개어 계층화하는 것도 좋을 것 같습니다.

위 예시와 마찬가지로 데이터도 각 변환 과정이 명확히 분리되어야하고, 각 과정에서 발생 한 장애등을 정확하게 확인 할 수 있어야 합니다.

## 그 외에도 많은 상황에 대한 데이터 거버넌스의 필요성

저의 경우에는 AD-HOC의 업무의 진행를 기반으로 말씀드렸지만, 이러한 실질적인 업무 효율 외에도 데이터 거버넌스의 범위인 개인정보 보호와 보안에 관련 한 내용도 데이터 거버넌스에 대한 필요성입니다.

위 예시들의 경우 주로 사용성 측면과 정확성 측면에 초점이 맞추어져 있음을 다시 한번 말씀드립니다.

# 데이터 카탈로그로의 확장

데이터 거버넌스를 알아가다보면 데이터 카탈로그에 대한 개념이 필수적으로 등장하게 됩니다. 여기서 **카탈로그는 상품에 대한 안내서, 상품 목록**으로 생각하면 쉽습니다. 저는 데이터 거버넌스가 필요 한 이유는 데이터가 곧 상품이기 때문이라는 말을 했습니다. 상품에 대한 목록이나 안내서가 없다면, 상품은 제대로 된 가치를 가질 수 없다는 것은 직관적으로 알고 있습니다.

예를들어 낡은 가게의 가판대 구석에 고디바 초콜릿이 놓여있을 때, 이 초콜릿이 고디바 초콜릿인지 목록에 적혀있지 않고 어떤 재료로 어떻게 만들어졌는지에 대한 안내서가 없으면 그 초콜릿은 저렴한 다른 초콜릿과 다르지 않는 가치가 낮은 초콜릿이 됩니다. 이러한 현상은 데이터를 다루는 과정에서도 자주 발생합니다.

보고서를 위해 임시로 작성 한 임시 테이블과 마케팅의 성과를 명확하게 측정 할 수 있도록 만들어진 대시보드를 위한 테이블이 카탈로그가 적절히 적혀 있지 않아서, 회사의 성과를 나타내는 특정 지표를 얻어 낼 때 우리는 활용 할 데이터를 혼동합니다. 왜냐하면 두 데이터는 비슷한 정보를 담고 있고, 어떤 데이터를 어떻게 가공했으며, 어떤 목적으로 만들어졌는지와 같은 메타데이터를 카탈로그화 하지 않았기 때문에 실제 해당 테이블을 만든 작업자의 지식 밖에서는 두 테이블은 모두 사용 가능하기 때문입니다.

우리는 데이터 카탈로그를 만드는 이유를 다음의 문장으로 표현합니다. 이 문장은 대부분의 관련 논문이나 기업 내 정의 문서에서도 비슷하게 사용됩니다.

**"데이터를 자산화한다."**

즉, 데이터 카탈로그를 구축하기 전까지 우리가 쌓는 데이터는 자산으로 활용되기 어렵다는 의미입니다.

데이터 카탈로그에 대한 내용은 "데이터 카탈로그 만들기"라는 책을 통해서 공부를 이어나가고 있으며 관련 내용은 [블로그 포스트](https://lion2me.github.io/posts/Data-Catalog-%EB%A7%8C%EB%93%A4%EA%B8%B0-Data-Catalog%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C/)로 지속적으로 업데이트하고 있습니다. 이 내용은 Data Lake 환경에서 데이터 카탈로그를 구축하는 방법과 유의 할 점을 위주로 적혀있습니다. 하지만, Data Lake 환경이 아니여도 Data Warehouse 혹은 Data Mart 환경에서도 이미 우리는 어느정도의 카탈로그를 가지고 있습니다. 스키마, 권한 등이 이미 어느정도는 플랫폼 내에서 관리되기 때문이죠.

# 데이터 카탈로그 구축을 선행

데이터 거버넌스에 대한 관심이 높아지고 심지어 관리를 시작하려는 시점이라면 거의 대부분의 경우 이미 어느정도의 카탈로그가 있는 상태라고 볼 수 있습니다.

카탈로그라는 어려운 단어를 사용하지만, 결국 상품의 목록과 안내서라는 측면에서 우리가 사용하는 데이터 플랫폼 내의 스키마에 대한 정보, 테이블에 대한 정보 등이 모두 카탈로그임을 대략적으로 이해 할 수 있습니다. 그리고 개발 초기부터 거버넌스를 염두하지 않은 데이터 환경을 구축했다면 이상적인 데이터 카탈로그를 쌓고 있지 않았음을 깨달을 수 있습니다.

그렇다면 데이터 카탈로그를 제대로 구축하는 것이 데이터 거버넌스 구축 중 가장 선행되어야 하는 사항이라고 생각 할 수 있습니다. 우리가 데이터 거버넌스로 관리 할 대상은 오직 데이터 카탈로그로 관리하는 데이터로 확정 짓는 것입니다. 우리는 유통기한이 지난 초콜릿(현재 사용하지 않는 데이터)를 모두 쓰레기통에 버릴 것 입니다.

하지만 이 주제에 대해 첫 문장처럼 대부분의 경우 이미 어느 정도의 카탈로그가 있는 상황입니다. 이 경우에는 어떻게 데이터 카탈로그를 잘 구축 할 수 있을까요?

## 데이터 디스커버리 구축의 선행

데이터 디스커버리 툴은 일반적으로 빠른 데이터의 검색을 위해 존재합니다. 그로인해 비즈니스 관계자들은 자신이 원하는 데이터가 이미 있는지, 혹은 어디서 쿼리 할 수 있는지를 검색을 통해서 얻을 수 있습니다. 추가적으로 해당 데이터가 만들어지기까지의 계보(Lineage)를 제공하기에 특정 테이블의 변화로 인해 발생 할 수 있는 영향을 빠르게 추적 할 수 있습니다.

우리는 이러한 데이터 디스커버리 툴을 선행하여 적용하는 것으로 많은 이점을 가져 갈 수 있습니다.

- 데이터 현황 파악
- 기존 데이터의 계보를 통한 플랫폼 이전 시 안정성 확보
- 메타데이터의 중앙 집중적 관리
- 오너십을 통한 데이터 관리 주체 설정
- 데이터 사용자 경험 최적화
- 도메인 및 태그를 통한 데이터 속성 분리
- 관련 히스토리 및 쿼리 등의 기록

이 외에도 많은 장단점이 있지만 생각나는 내용에 대해서 적으면 위와 같습니다. 보통 데이터 카탈로그가 적절히 적재 된 뒤에 데이터 디스커버리 플랫폼을 구축하는 것이라고 생각 할 수 있지만, 저의 개인적인 생각으로는 반대로 디스커버리 플랫폼을 선행하는 것이 좋다고 생각합니다. 그 이유는 바로 **"데이터 현황 파악"** 과 **"계보에 대한 파악"** 이 가능하기 때문입니다.

우리는 데이터 카탈로그를 구축하는 과정에서 다양한 데이터 플랫폼을 함께 적용 할 가능성이 높습니다. HDFS를 사용하면 HIVE 기반의 개별적인 메타데이터 스토리지를 구축 할 수 있고, Glue Catalog와 같은 클라우드 플랫폼을 활용 할 수 있습니다. 이 과정에서 몇몇 데이터의 경우에는 더 적절한 플랫폼으로 이전 할 수 있고, 필요 없는 데이터를 파악하고 삭제하거나 더 이상 사용되지 않음을 표시 할 수 있습니다. 이 때 데이터 디스커버리를 활용하면 이러한 데이터를 보다 쉽게 파악 할 수 있습니다.

# 정리

1. 데이터의 사용성과 정확성에 대해 어려움을 겪고 있는 상황이라면 데이터 거버넌스를 보장하기 위한 노력이 필요 할 수 있다.

2. 적절한 중간 데이터를 구축하고 데이터 카탈로그를 통해 자산화하는 것은 데이터 사용성과 정확성을 크게 향상 시킬 수 있다.

3. 데이터의 자산화를 수행하는 도중 현재 데이터에 대한 현황 파악 및 각 데이터에 대한 영향도를 추정 할 필요가 있으며, 이 경우 데이터 디스커버리 툴은 좋은 길잡이가 될 수 있다.

# 의견

저는 데이터 거버넌스를 보장하기 위한 업무를 처음 시작했을 때 어디부터 시작해야 할 지 혼란스러워하며 제대로 진행하지 못한 경험이 있습니다. 아직도 데이터 거버넌스에 관련한 업무를 자원하여 더 나은 환경을 구축하기위해 노력 중 입니다. 이 과정에서 얻은 견해는 "데이터 거버넌스는 혼자 할 수 없다" 입니다.

일전에 읽은 논문에서는 "중앙집중식 관리"와 "분리식 관리"로 데이터 거버넌스의 관리 주체에 대한 사항을 본 적이 있습니다. 두 방식은 모두 장단점이 있으며 어떤 방식을 택할 것 인지는 사업의 규모와 도메인등에 따라 다를 것으로 보입니다. 하지만 확실 한 것은 데이터 거버넌스를 보장하는 것은 개인이 아닌 함께 업무를 하는 비즈니스 관계자, 데이터 팀 모두에게 영향을 주는 것이라는 것을 알 수 있었습니다.

더 자세한 내용에 대해서는 추후에 포스트하도록 하겠습니다.
